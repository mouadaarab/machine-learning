#!/usr/bin/env python3
"""
Script pour cr√©er et sauvegarder des mod√®les AdaBoost 
entra√Æn√©s sur les datasets Iris et California Housing.

Ce script cr√©e deux mod√®les AdaBoost :
1. AdaBoostClassifier pour la classification des esp√®ces d'iris
2. AdaBoostRegressor pour la pr√©diction des prix immobiliers californiens
"""

import os
import joblib
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris, fetch_california_housing
from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    mean_squared_error, r2_score
)


def create_adaboost_iris_model():
    """
    Cr√©e et sauvegarde un mod√®le AdaBoost pour la classification des esp√®ces d'iris.
    
    Returns:
        AdaBoostClassifier: Le mod√®le entra√Æn√©
        dict: Informations sur les performances du mod√®le
    """
    print("\n" + "="*60)
    print("üå∏ Cr√©ation du mod√®le AdaBoost pour la classification Iris...")
    
    # Charger le dataset Iris
    iris = load_iris()
    X = iris.data
    y = iris.target
    feature_names = iris.feature_names
    target_names = iris.target_names
    
    print(f"üìä Dataset charg√© avec succ√®s:")
    print(f"   - Nombre d'√©chantillons: {X.shape[0]}")
    print(f"   - Nombre de features: {X.shape[1]}")
    print(f"   - Classes: {target_names}")
    
    # Diviser les donn√©es
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"‚úÇÔ∏è  Division des donn√©es:")
    print(f"   - Entra√Ænement: {X_train.shape[0]} √©chantillons")
    print(f"   - Test: {X_test.shape[0]} √©chantillons")
    
    # Cr√©er et entra√Æner le mod√®le AdaBoost
    print("üöÄ Entra√Ænement du mod√®le AdaBoost...")
    
    # Estimateur de base : DecisionTree avec profondeur limit√©e (weak learner)
    base_estimator = DecisionTreeClassifier(max_depth=1, random_state=42)
    
    ada_classifier = AdaBoostClassifier(
        estimator=base_estimator,
        n_estimators=100,          # Nombre d'estimateurs faibles
        learning_rate=1.0,         # Taux d'apprentissage
        algorithm='SAMME',         # Algorithme SAMME
        random_state=42
    )
    
    ada_classifier.fit(X_train, y_train)
    
    # √âvaluer le mod√®le
    print("üìà √âvaluation du mod√®le...")
    
    # Pr√©dictions sur l'ensemble de test
    y_pred = ada_classifier.predict(X_test)
    
    # Calculer l'accuracy
    accuracy = accuracy_score(y_test, y_pred)
    print(f"üéØ Accuracy sur l'ensemble de test: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # Validation crois√©e
    cv_scores = cross_val_score(ada_classifier, X, y, cv=5)
    print(f"üîÑ Validation crois√©e (5-fold):")
    print(f"   - Score moyen: {cv_scores.mean():.4f} (¬±{cv_scores.std()*2:.4f})")
    
    # Rapport de classification d√©taill√©
    print("\nüìã Rapport de classification:")
    print(classification_report(y_test, y_pred, target_names=target_names))
    
    # Matrice de confusion
    print("üî¢ Matrice de confusion:")
    cm = confusion_matrix(y_test, y_pred)
    print(cm)
    
    # Importance des features (moyenne des importances des estimateurs)
    print("\nüèÜ Importance des features:")
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': ada_classifier.feature_importances_
    }).sort_values('importance', ascending=False)
    
    for idx, row in feature_importance.iterrows():
        print(f"   {row['feature']}: {row['importance']:.4f}")
    
    # Sauvegarder le mod√®le
    models_dir = 'models_ai'
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)
    
    model_path = os.path.join(models_dir, 'adaboost_iris_model.pkl')
    joblib.dump(ada_classifier, model_path)
    
    # Informations sur le mod√®le
    model_info = {
        'model_type': 'AdaBoostClassifier',
        'features': list(feature_names),
        'target_names': list(target_names),
        'n_estimators': 100,
        'learning_rate': 1.0,
        'accuracy': accuracy,
        'cv_mean_score': cv_scores.mean(),
        'cv_std_score': cv_scores.std(),
        'feature_importance': feature_importance.to_dict('records'),
        'confusion_matrix': cm.tolist(),
        'algorithm': 'SAMME',
        'base_estimator': 'DecisionTreeClassifier(max_depth=1)'
    }
    
    info_path = os.path.join(models_dir, 'adaboost_iris_model_info.pkl')
    joblib.dump(model_info, info_path)
    
    print(f"\nüíæ Mod√®le sauvegard√© vers: {model_path}")
    print(f"üíæ Informations sauvegard√©es vers: {info_path}")
    
    return ada_classifier, model_info


def create_adaboost_housing_model():
    """
    Cr√©e et sauvegarde un mod√®le AdaBoost pour la r√©gression des prix immobiliers californiens.
    
    Returns:
        AdaBoostRegressor: Le mod√®le entra√Æn√©
        dict: Informations sur les performances du mod√®le
    """
    print("\n" + "="*60)
    print("üè† Cr√©ation du mod√®le AdaBoost pour la r√©gression California Housing...")
    
    # Charger le dataset California Housing
    california_housing = fetch_california_housing()
    X = california_housing.data
    y = california_housing.target
    feature_names = california_housing.feature_names
    
    print(f"üìä Dataset charg√© avec succ√®s:")
    print(f"   - Nombre d'√©chantillons: {X.shape[0]}")
    print(f"   - Nombre de features: {X.shape[1]}")
    print(f"   - Features: {list(feature_names)}")
    print(f"   - Variable cible: Prix des maisons (en centaines de milliers de dollars)")
    
    # Diviser les donn√©es
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"‚úÇÔ∏è  Division des donn√©es:")
    print(f"   - Entra√Ænement: {X_train.shape[0]} √©chantillons")
    print(f"   - Test: {X_test.shape[0]} √©chantillons")
    
    # Cr√©er et entra√Æner le mod√®le AdaBoost
    print("üöÄ Entra√Ænement du mod√®le AdaBoost...")
    
    # Estimateur de base : DecisionTree avec profondeur limit√©e (weak learner)
    base_estimator = DecisionTreeRegressor(max_depth=4, random_state=42)
    
    ada_regressor = AdaBoostRegressor(
        estimator=base_estimator,
        n_estimators=100,          # Nombre d'estimateurs faibles
        learning_rate=1.0,         # Taux d'apprentissage
        loss='linear',             # Fonction de perte lin√©aire
        random_state=42
    )
    
    ada_regressor.fit(X_train, y_train)
    
    # Faire des pr√©dictions
    y_pred = ada_regressor.predict(X_test)
    
    # Calculer les m√©triques
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    
    print(f"\nüìà Performance du mod√®le:")
    print(f"   - Mean Squared Error: {mse:.4f}")
    print(f"   - Root Mean Squared Error: {rmse:.4f}")
    print(f"   - R¬≤ Score: {r2:.4f}")
    
    # Importance des features
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': ada_regressor.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nüèÜ Importance des features:")
    for idx, row in feature_importance.iterrows():
        print(f"   {row['feature']}: {row['importance']:.4f}")
    
    # Sauvegarder le mod√®le
    models_dir = 'models_ai'
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)
    
    model_path = os.path.join(models_dir, 'adaboost_housing_model.pkl')
    joblib.dump(ada_regressor, model_path)
    
    # Informations sur le mod√®le
    model_info = {
        'model_type': 'AdaBoostRegressor',
        'features': list(feature_names),
        'n_estimators': 100,
        'learning_rate': 1.0,
        'loss': 'linear',
        'mse': mse,
        'rmse': rmse,
        'r2_score': r2,
        'feature_importance': feature_importance.to_dict('records'),
        'base_estimator': 'DecisionTreeRegressor(max_depth=4)'
    }
    
    info_path = os.path.join(models_dir, 'adaboost_housing_model_info.pkl')
    joblib.dump(model_info, info_path)
    
    print(f"\nüíæ Mod√®le sauvegard√© vers: {model_path}")
    print(f"üíæ Informations sauvegard√©es vers: {info_path}")
    
    return ada_regressor, model_info


def test_models():
    """
    Teste les mod√®les AdaBoost sauvegard√©s avec des exemples.
    """
    print("\n" + "="*60)
    print("üß™ Test des mod√®les AdaBoost...")
    
    # Test du mod√®le Iris
    print("\nüå∏ Test du mod√®le AdaBoost Iris:")
    iris_model = joblib.load('models_ai/adaboost_iris_model.pkl')
    
    # Exemples de test pour Iris
    test_samples = [
        [5.1, 3.5, 1.4, 0.2],  # Setosa typique
        [7.0, 3.2, 4.7, 1.4],  # Versicolor typique
        [6.3, 3.3, 6.0, 2.5]   # Virginica typique
    ]
    
    sample_names = ['Setosa typique', 'Versicolor typique', 'Virginica typique']
    class_names = ['Setosa', 'Versicolor', 'Virginica']
    
    for i, (sample, name) in enumerate(zip(test_samples, sample_names)):
        prediction = iris_model.predict([sample])[0]
        probability = iris_model.predict_proba([sample])[0]
        
        print(f"   {name}:")
        print(f"      Features: {sample}")
        print(f"      Pr√©diction: {class_names[prediction]}")
        print(f"      Probabilit√©s: {dict(zip(class_names, probability.round(4)))}")
    
    # Test du mod√®le Housing
    print("\nüè† Test du mod√®le AdaBoost Housing:")
    housing_model = joblib.load('models_ai/adaboost_housing_model.pkl')
    
    # Exemple de test pour Housing (valeurs moyennes)
    test_house = [8.3252, 41.0, 6.98, 1.02, 322.0, 2.56, 37.88, -122.23]
    prediction = housing_model.predict([test_house])[0]
    
    print(f"   Maison d'exemple:")
    print(f"      Features: {test_house}")
    print(f"      Prix pr√©dit: ${prediction:.2f}00 (centaines de milliers)")


def main():
    """
    Fonction principale pour cr√©er les mod√®les AdaBoost.
    """
    print("üöÄ Cr√©ation des mod√®les AdaBoost")
    print("=" * 60)
    
    try:
        # Cr√©er les mod√®les
        iris_model, iris_info = create_adaboost_iris_model()
        housing_model, housing_info = create_adaboost_housing_model()
        
        # Tester les mod√®les
        test_models()
        
        print("\n" + "="*60)
        print("üéâ Mod√®les AdaBoost cr√©√©s avec succ√®s!")
        print(f"üìà Iris Classification - Accuracy: {iris_info['accuracy']:.2f}%")
        print(f"üìà California Housing - R¬≤ Score: {housing_info['r2_score']:.4f}")
        print("\nLes mod√®les sont pr√™ts √† √™tre utilis√©s dans votre application Django.")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la cr√©ation des mod√®les: {str(e)}")
        raise


if __name__ == "__main__":
    main()
